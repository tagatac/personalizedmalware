\documentclass{article}
\usepackage{enumerate}

\begin{document}
\begin{center}
	\Large Personalized Malware - Research Plan
\end{center}
\section{Idea}
The main question is whether publicly available (or easily obtained) information about individuals or groups of people can be used to tailor malware or attacks against those individuals or groups.  This type of attack can be considered a generalization of - or the malware/exploit form of - spear phishing.  Where spear phishing requires the victim to make a mistake and fall prey to the targeted social engineering attack, personalized malware seeks to use the information gained about the individual to
\begin{enumerate}[a)]
	\itemsep0em
	\item increase the effectiveness of the exploit or malware, and/or
	\item decrease its detectability,
\end{enumerate}
without any requirement that the victim fail to follow some security protocol.
\section{Information About Individuals}
Configuration fingerprinting has been studied as a way to achieve the same two goals above.  Thus, for this study, we consider only information which allows for prediction of future behavior.  I believe this information can be completely contained in the following three categories:
\begin{itemize}
	\itemsep0em
	\item Past Behavior: any log or record of prior behavior - the more similar to the class of behavior we want to predict, the more relevant;
	\item Interests: those topics and categories of activities, ideas, and information that the individual enjoys interacting with the most;
	\item Values: those ideas or resources that the individual considers to be most important.
\end{itemize}
\section{Experiments}
\begin{enumerate}
	\itemsep0em
	\item \textbf{Masquerader detection evasion}: Behavior modeling is an important tool for detecting attempts by an attacker to pretend to be a legitimate user in order to make use of the access rights of the legitimate user (where the access to the legitimate user’s account was obtained in some technical or non-technical way).  With information about the legitimate user’s past behavior, an attacker could piece together “gadgets” of legitimate action sequences (drawn from the history) to obtain the desired result.  This is analogous to ROP attacks which use gadgets of existing code to generate arbitrary malicious code.
	\begin{enumerate}[a.]
		\item A specific experiment would be to obtain such histories of search behavior~\cite{Salem2011}, construct gadget-based attacks as described above, and test existing masquerade detection methods against these attacks.  This experiment can use some user's data from the RUU dataset from Ben Salem's work as the history and the basis for the gadgets.  A second user can be considered a masquerader, and their search activity altered to achieve the same search coverage and order, but either interspersed with, or refactored as gadgets of, the first user's behavior.  Successful evasion would be evaluated as a low anomaly detection rate using ocSVM AD as in \cite{Salem2011}.
		\item A second experiment would be to somehow predict search behavior based on interests and/or values.  One way to do this might be to assign a relevance score for each document for each interest.  For example, if the interest is fishing, documents with references to specific fish, bait, fishing rods, etc. would be scored highly.  A model for search behavior could be constructed using these scores and some observed search behavior by people for whom we know their interests.  This model could then be applied to a filesystem, knowing only the user's interests (assumed to have been obtained against the user's will).  A similar AD system as in a. could be trained using real data, and then the model-generated behavior could be checked for anomalous activity (as reported by the AD system).  Taking this further, some malicious search activity could be hidden within gadgets of the search activity generated by the model, or alternatively, a script could take the malicious search activity as input and generate malicious search activity consistent with the model.
	\end{enumerate}
	\item \textbf{Botnet detection evasion}: 
\end{enumerate}
\section{(non-comprehensive) Related Work}
\begin{enumerate}
	\itemsep0em
	\item \textbf{Mimicry attacks}~\cite{Wagner2002}: Wagner and Soto delineate a framework for sequences of events that an attacker can use to achieve their malicious goal without being detected by anomaly-based IDS’s.  In an example implementation, they space out a malicious sequence of system calls by padding them with benign system calls which have no effect.
	\item \textbf{Behavior modeling}~\cite{Greitzer2011a}: 
	\item \textbf{Botnet detection}~\cite{Zhao2013,Dietrich2013}: Zhao et al. 
\end{enumerate}

{\footnotesize \bibliographystyle{acm}
\bibliography{references}}
\end{document}