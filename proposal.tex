\documentclass{article}
\usepackage{enumerate,hyperref}
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}

\begin{document}
\begin{center}
	\Large Personalized Malware - Research Ideas
\end{center}
\section{Idea}
The main question is whether publicly available (or easily obtained) information about individuals or groups of people can be used to tailor malware or attacks against those individuals or groups.  This type of attack can be considered a generalization of --- or the malware/exploit form of --- spear phishing.  Where spear phishing requires the victim to make a mistake and fall prey to the targeted social engineering attack, personalized malware seeks to use the information gained about the individual to
\begin{enumerate}[a)]
	\itemsep0em
	\item increase the effectiveness of the exploit or malware, and/or
	\item decrease its detectability,
\end{enumerate}
without any requirement that the victim fail to follow some security protocol.  If a viable attack vector, this class of attacks speaks to the importance of protecting online privacy.
\section{Information About Individuals}
Configuration fingerprinting has been studied as a way to achieve the same two goals above.  Thus, for this study, we consider only information which allows for prediction of future behavior.  I believe this information can be completely contained in the following three categories:
\begin{itemize}
	\itemsep0em
	\item Past Behavior: any log or record of prior behavior - the more similar to the class of behavior we want to predict, the more relevant;
	\item Interests: those topics and categories of activities, ideas, and information that the individual enjoys interacting with the most;
	\item Values: those ideas or resources that the individual considers to be most important.
\end{itemize}
\section{Experiments}
\begin{enumerate}
	\itemsep0em
	\item \textbf{Masquerader detection evasion}: Behavior modeling is an important tool for detecting attempts by an attacker to pretend to be a legitimate user in order to make use of the access rights of the legitimate user (where the access to the legitimate user’s account was obtained in some technical or non-technical way).  With information about the legitimate user’s past behavior, an attacker could piece together “gadgets” of legitimate action sequences (drawn from the history) to obtain the desired result.  This is analogous to ROP attacks which use gadgets of existing code to generate arbitrary malicious code.
	\begin{enumerate}[a.]
		\item A specific experiment would be to obtain such histories of search behavior~\cite{Salem2011}, construct gadget-based attacks as described above, and test existing masquerade detection methods against these attacks.  This experiment can use some user's data from the RUU dataset from Ben Salem's work as the history and the basis for the gadgets.  A second user can be considered a masquerader, and their search activity altered to achieve the same search coverage and order, but either interspersed with, or refactored as gadgets of, the first user's behavior.  Successful evasion would be evaluated as a low anomaly detection rate using ocSVM AD as in \cite{Salem2011}.
		\item A second experiment would be to somehow predict search behavior based on interests and/or values.  One way to do this might be to assign a relevance score for each document for each interest.  For example, if the interest is fishing, documents with references to specific fish, bait, fishing rods, etc. would be scored highly.  Semantic processing libraries may help with this (e.g. \href{http://www.nltk.org/book/}{NLTK}).  A model for search behavior could be constructed using these scores and some observed search behavior by people for whom we know their interests.  This model could then be applied to a filesystem, knowing only the user's interests (assumed to have been obtained against the user's will).  A similar AD system as in a. could be trained using real data, and then the model-generated behavior could be checked for anomalous activity (as reported by the AD system).  Taking this further, some malicious search activity could be hidden within gadgets of the search activity generated by the model, or alternatively, a script could take the malicious search activity as input and generate malicious search activity consistent with the model.
	\end{enumerate}
	\item \textbf{Targeted logic bombs}: Logic bombs are pieces of code intentionally inserted into software that will set off a malicious function when specified conditions are met.  Viruses often use the condition that the system time passes a certain time, triggering the payload on that date.  One could imagine, however, a different, much more targeted condition --- one that is likely to be met by only a single user or a subset of users.  For example, a keylogger that waits for a specific username to be entered on a specific website before transmitting the logged password is much less likely to be detected by network traffic analyses than one which transmits periodically, or after every password is typed.  Taking this further, if a virus writer can use a person's interests to guess a condition that the target is likely to meet, but that others are unlikely to meet, targeted logic bombs certainly fall into the category of personalized malware.

An experiment in this space could be to (in a similar way to experiment 1b), correlate user actions (e.g. filesystem search behavior, web searches, specific URLs visited) with known user interests.  This data in aggregate can be used to identify rare actions in general, but common actions among users sharing an interest.  Success would be evaluated by using interests collected for new users to predict some condition that each user is likely to meet (but that all other users are unlikely to meet), and checking if the user actually meets that condition.
	\item \textbf{Botnet detection evasion}: I had an idea to evade botnet detection by using users' interests to make botnet actions look more legitimate for the compromised machine, but ML methods at the network level will probably invalidate this evasion technique.
\end{enumerate}
\section{Sampling of Related Work}
\begin{enumerate}
	\itemsep0em
	\item \textbf{Mimicry attacks}~\cite{Wagner2002}: Wagner and Soto delineate a framework for sequences of events that an attacker can use to achieve their malicious goal without being detected by anomaly-based IDS’s.  In an example implementation, they space out a malicious sequence of system calls by padding them with benign system calls which have no effect.
	\item \textbf{Behavior modeling}~\cite{Greitzer2011a}: Greitzer developed a framework for modeling human behavior in a domain-agnostic way.
	\item \textbf{Botnet detection}~\cite{Zhao2013,Dietrich2013}: Zhao et al. demonstrated that it is possible to identify botnets using network traffic.  Dietrich et al. demonstrated CoCoSpot, a system that can identify botnet command and control flows, also using network traffic.
\end{enumerate}

{\footnotesize \bibliographystyle{acm}
\bibliography{references}}
\end{document}