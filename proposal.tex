\documentclass{article}
\usepackage{enumerate,hyperref,textcomp}
%\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}

\title{Research Ideas on Personalized Malware}
\author{David Tagatac\\dtagatac@cs.columbia.edu}

\begin{document}
\maketitle
\section{Idea}
The main question is whether publicly available (or easily obtained) information about individuals or groups of people can be used to tailor malware or attacks against those individuals or groups.
This type of attack can be considered a generalization of --- or the malware/exploit form of --- spear phishing.
Where spear phishing requires the victim to make a mistake and fall prey to the targeted social engineering attack, personalized malware seeks to use the information gained about the individual to
\begin{enumerate}[a)]
	%\itemsep0em
	\item increase the effectiveness of the exploit or malware, and/or
	\item decrease its detectability,
\end{enumerate}
without any requirement that the victim fail to follow some security protocol.
If it is a viable attack vector, this class of attacks speaks to the importance of protecting online privacy.

\section{Information About Individuals}
Configuration fingerprinting has been studied as a way to achieve the same two goals above.
Thus, for this study, we consider only information which allows for prediction of future behavior.
I believe this information can be completely contained in the following three categories:
\begin{itemize}
	%\itemsep0em
	\item Past Behavior: any log or record of prior behavior - the more similar to the class of behavior we want to predict, the more relevant;
	\item Interests: those topics and categories of activities, ideas, and information that the individual enjoys interacting with the most;
	\item Values: those ideas or resources that the individual considers to be most important.
\end{itemize}

\section{Data Collection}
For the purposes of demonstrating this class of attacks, information about individuals can be obtained at low cost in several concrete ways:
\begin{itemize}
	\item \textbf{Placing ads}: Ads purchased with ad networks can be used to place cookies across the web in a limited way, allowing for the fingerprinting of individuals by their limited web history.
	It may be expensive to place enough ads to get a sizable history however.
	\item \textbf{Participating in ad exchange auctions}~\cite{Olejnik2014}: Rather than placing ads, simply bidding on ads exposes users' web histories.
	Cookie matching may allow for expanded histories by associating histories obtained from one auction with those of the same users obtained from another auction.
	\item \textbf{Private data exchanges}: It may be possible to buy web histories or even profiles directly from publishers.
	See, e.g., this solution for publishers to sell this data: \url{http://exelate.com/newsite/wp-content/uploads/2014/06/eXelate-eXchange-July-2014.pdf}
	\item \textbf{Search results}: Simply searching for users via Google, or mining public data on Facebook and/or Google+ profiles, can provide enormous amounts of information about individuals.
	\item \textbf{Existing databases}: Compiled lists of compromised passwords, databases of past user behavior, etc. are available from other researchers.
\end{itemize}

\section{Applying Information About Individuals to New Attacks}
\subsection{Malicious Advertisement Efficacy}
This attack uses users' web histories to make malicious ad-purchasing more cost-effective.
\begin{enumerate}
	\item Obtain users' web histories by bidding in ad exchange auctions~\cite{Olejnik2014}.
	\item Obtain firewall and malware detection logs from Symantec, Trend Micro, or the like.
	\item Apply collaborative filtering (as in~\cite{Jiang2014}) to rank the likelihood of infection by various exploits for users based on their web history.
	\item The attack is then to purchase malicious ads for users whose web histories indicate they are susceptible to Javascript or other ad-deliverable exploits.
	\item This attack can be evaluated by purchasing ads that only test the exploit without delivering any payload.
\end{enumerate}
\subsection{Combining Configuration Details with Identity}
This attack uses users' system configurations to launch targeted attacks on those users' servers.
\begin{enumerate}
	\item Mine GitHub for code that indicates the presence of exploit-prone software.
	\item Search the web for public profiles for the same name and/or username.
	\item Try this exploit on any link in any of those profiles.
	\item This attack can be evaluated by testing the exploit without modifying the compromised system in any way.
\end{enumerate}

\section{Applying Information About Individuals to Old Attacks}
\begin{enumerate}
	%\itemsep0em
	\item \textbf{Masquerader detection evasion}: Behavior modeling is an important tool for detecting attempts by an attacker to pretend to be a legitimate user in order to make use of the access rights of the legitimate user (where the access to the legitimate user’s account was obtained in some technical or non-technical way).
	With information about the legitimate user’s past behavior, an attacker could piece together “gadgets” of legitimate action sequences (drawn from the history) to obtain the desired result.
	This is analogous to ROP attacks which use gadgets of existing code to generate arbitrary malicious code.
	\begin{enumerate}[a.]
		\item A specific experiment would be to obtain such histories of search behavior~\cite{Salem2011}, construct gadget-based attacks as described above, and test existing masquerade detection methods against these attacks.
		This experiment can use some user's data from the RUU dataset from Ben Salem's work as the history and the basis for the gadgets.
		A second user can be considered a masquerader, and their search activity altered to achieve the same search coverage and order, but either interspersed with, or refactored as gadgets of, the first user's behavior.
		Successful evasion would be evaluated as a low anomaly detection rate using ocSVM AD as in \cite{Salem2011}.
		\item A second experiment would be to somehow predict search behavior based on interests and/or values.
		One way to do this might be to assign a relevance score for each document for each interest.
		For example, if the interest is fishing, documents with references to specific fish, bait, fishing rods, etc. would be scored highly.
		Semantic processing libraries may help with this (e.g. NLTK \textlangle\url{http://www.nltk.org/book/}\textrangle).
		A model for search behavior could be constructed using these scores and some observed search behavior by people for whom we know their interests.
		This model could then be applied to a filesystem, knowing only the user's interests (assumed to have been obtained against the user's will).
		A similar AD system as in a. could be trained using real data, and then the model-generated behavior could be checked for anomalous activity (as reported by the AD system).
		Taking this further, some malicious search activity could be hidden within gadgets of the search activity generated by the model, or alternatively, a script could take the malicious search activity as input and generate malicious search activity consistent with the model.
	\end{enumerate}
	\item \textbf{Targeted logic bombs}: Logic bombs are pieces of code intentionally inserted into software that will set off a malicious function when specified conditions are met.
	Viruses often use the condition that the system time passes a certain time, triggering the payload on that date.
	One could imagine, however, a different, much more targeted condition --- one that is likely to be met by only a single user or a subset of users.
	For example, a keylogger that waits for a specific username to be entered on a specific website before transmitting the logged password is much less likely to be detected by network traffic analyses than one which transmits periodically, or after every password is typed.
	Taking this further, if a virus writer can use a person's interests to guess a condition that the target is likely to meet, but that others are unlikely to meet, targeted logic bombs certainly fall into the category of personalized malware.
	\begin{enumerate}[a.]
		\item An experiment in this space could be to (in a similar way to experiment 1b), correlate user actions (e.g. filesystem search behavior, web searches, specific URLs visited) with known user interests.
		This data in aggregate can be used to identify rare actions in general, but common actions among users sharing an interest.
		Success would be evaluated by using interests collected for new users to predict some condition that each user is likely to meet (but that all other users are unlikely to meet), and checking if the user actually meets that condition.
	\end{enumerate}
	\item \textbf{Botnet detection evasion}: I had an idea to evade botnet detection by using users' interests to make botnet actions look more legitimate for the compromised machine, but ML methods at the network level will probably invalidate this evasion technique.
\end{enumerate}

\section{Sampling of Related Work}
\begin{enumerate}
	%\itemsep0em
	\item \textbf{Mimicry attacks}~\cite{Wagner2002}: Wagner and Soto delineate a framework for sequences of events that an attacker can use to achieve their malicious goal without being detected by anomaly-based IDS’s.
	In an example implementation, they space out a malicious sequence of system calls by padding them with benign system calls which have no effect.
	\item \textbf{Behavior modeling}~\cite{Greitzer2011a}: Greitzer developed a framework for modeling human behavior in a domain-agnostic way.
	\item \textbf{Botnet detection}~\cite{Zhao2013,Dietrich2013}: Zhao et al. demonstrated that it is possible to identify botnets using network traffic.
	Dietrich et al. demonstrated CoCoSpot, a system that can identify botnet command and control flows, also using network traffic.
	\item \textbf{Personalized malware warning system}~\cite{Jiang2014}: Jiang et al. applied collaborative filtering to malware detection logs in order to rank malware by current or future infection likelihood for individual users.
	\item \textbf{Secret questions}~\cite{Schechter2009}: Schechter et al. showed that `secret' questions used to recover account access in the event of a forgotten password are unreliable (people forget their answers) and insecure (the answers are easier to guess than passwords).
\end{enumerate}

{\footnotesize \bibliographystyle{acm}
\bibliography{references}}
\end{document}